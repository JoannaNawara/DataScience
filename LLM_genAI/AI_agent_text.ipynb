{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy9UeeRqIeG9",
        "outputId": "538f40e8-a1c0-4c5e-a60f-010773a7060f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrZPL0NkssQx",
        "outputId": "7d369bc3-f02a-4db8-d3f1-31ab8ac8bae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.51)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.24)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain_community-0.3.21 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpjg0xCQuih1",
        "outputId": "34bcfdac-2bd0-496b-e798-6e63764c178b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.30.1)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.3.51)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.50.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.13.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.3.24)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.11.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6VOQKdjxR67",
        "outputId": "c548d452-9e67-4a55-a901-aeac54809673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT_vgAcFgVWz"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLlORRzKrg0l"
      },
      "outputs": [],
      "source": [
        "pdf_folder = \"/content/\"\n",
        "\n",
        "def extract_text_from_pdfs(pdf_folder):\n",
        "    texts = {}\n",
        "    for pdf_file in os.listdir(pdf_folder):\n",
        "        if pdf_file.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "            reader = PdfReader(pdf_path)\n",
        "            text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "            texts[pdf_file] = text\n",
        "    return texts\n",
        "\n",
        "pdf_texts = extract_text_from_pdfs(pdf_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrzytXYdslyJ"
      },
      "outputs": [],
      "source": [
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "documents_with_embeddings = []\n",
        "\n",
        "for pdf_name, text in pdf_texts.items():\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    embeddings = embedding_model.embed_documents(chunks)\n",
        "    documents_with_embeddings.extend(zip(chunks, embeddings))\n",
        "\n",
        "vectorstore = FAISS.from_embeddings(documents_with_embeddings, embedding_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF3Qmnp2xe_s",
        "outputId": "a9cb401a-206b-44d5-9af9-6933378a064e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Podzielono tekst w s11356-021-13769-x.pdf na 108 fragmentów.\n",
            "Zakonczono embeddingi dla s11356-021-13769-x.pdf.\n",
            "Podzielono tekst w 1-s2.0-S0045653521030599-main.pdf na 129 fragmentów.\n",
            "Zakonczono embeddingi dla 1-s2.0-S0045653521030599-main.pdf.\n",
            "Podzielono tekst w 1-s2.0-S0048969721030722-main.pdf na 125 fragmentów.\n",
            "Zakonczono embeddingi dla 1-s2.0-S0048969721030722-main.pdf.\n",
            "Podzielono tekst w 1-s2.0-S0013935122001827-main.pdf na 130 fragmentów.\n",
            "Zakonczono embeddingi dla 1-s2.0-S0013935122001827-main.pdf.\n",
            "Podzielono tekst w 1-s2.0-S0043135417309272-main.pdf na 94 fragmentów.\n",
            "Zakonczono embeddingi dla 1-s2.0-S0043135417309272-main.pdf.\n",
            "Znalazłem 1172 par (tekst, embedding).\n"
          ]
        }
      ],
      "source": [
        "# Sprawdzenie, czy teksty zostały prawidłowo rozbite\n",
        "for pdf_name, text in pdf_texts.items():\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    if not chunks:\n",
        "        print(f\"Brak tekstu w dokumencie {pdf_name}\")\n",
        "    else:\n",
        "        print(f\"Podzielono tekst w {pdf_name} na {len(chunks)} fragmentów.\")\n",
        "\n",
        "    embeddings = embedding_model.embed_documents(chunks)\n",
        "    if len(embeddings) != len(chunks):\n",
        "        print(f\"Problem z embeddingami w {pdf_name}, oczekiwano {len(chunks)}, a otrzymano {len(embeddings)}.\")\n",
        "    else:\n",
        "        print(f\"Zakonczono embeddingi dla {pdf_name}.\")\n",
        "\n",
        "    documents_with_embeddings.extend(zip(chunks, embeddings))\n",
        "\n",
        "print(f\"Znalazłem {len(documents_with_embeddings)} par (tekst, embedding).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aImtTLHOhijx",
        "outputId": "fa11743a-7ccd-43a7-9298-32ed04cb0220"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Define pipeline with optimized settings\n",
        "text_gen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"facebook/opt-1.3b\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,  # Faster inference\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.7,  # Controls randomness (lower = more precise)\n",
        "    top_k=50,  # Filters out low-probability words\n",
        "    top_p=0.9,  # Nucleus sampling (limits unlikely words)\n",
        "    repetition_penalty=1.2,\n",
        "    do_sample = True\n",
        ")\n",
        "\n",
        "# Wrap in LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEu310b2s7UX"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9VQcq-F3ypE"
      },
      "outputs": [],
      "source": [
        "def log_interaction(query, response, log_file=\"qa_logs.txt\"):\n",
        "    \"\"\"\n",
        "    Logs the user query and model response to a file with a timestamp.\n",
        "\n",
        "    Args:\n",
        "        query (str): The input query from the user.\n",
        "        response (str): The model's response.\n",
        "        log_file (str): The file to store logs (default: \"qa_logs.txt\").\n",
        "    \"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    log_entry = f\"{timestamp}\\nQuestion: {query}\\nResponse: {response}\\n{'-'*50}\\n\"\n",
        "\n",
        "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(log_entry)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvjvC2R3VEG9"
      },
      "outputs": [],
      "source": [
        "def ask_question(question):\n",
        "    result = qa_chain.invoke({\"query\": question})\n",
        "    response = result['result'].split(\"Helpful Answer:\")[-1].strip()\n",
        "    log_interaction(question, response)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxjVD-TqVJq6",
        "outputId": "177d8f52-faff-4ec1-9005-c723f815232e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Microplastic contamination increases microbial diversity in soils and\n",
            "water environments where they accumulate and biodegrade, thus increasing the potential\n",
            "for microbial health benefits. A recent study found that microbes living on microplastis-\n",
            "tic surfaces are more resistant than those living on other types of plastic particles\n",
            "when exposed to UV radiation (Hahn et al., 2020). Therefore, it is likely that\n",
            "microbiomes with diverse populations have higher rates of microbial adaptation\n",
            "to the environmental conditions encountered in agriculture and aquaculture.\n",
            "To illustrate this point, we examined the effects of two different plastics, one\n",
            "made out of polyethylene terephthalate (PET), and another made from polypropylenes\n",
            "(PP), on bacteria communities using a method called DNA polymerase chain re-\n",
            "action (PCR)-mediated amplification. We found that while both plastics increased the\n",
            "number of cells present in the environment, PET had the largest increase. This\n",
            "increased cell density was accompanied by an increase in the number of genes expressed\n",
            "in these cells. These changes occurred even though the plastic contained no antibiotics.\n",
            "We believe that this indicates that certain bacteria are better able to adapt to\n",
            "different plastics depending upon how they are being ingested. Additionally, our\n",
            "study showed that bacteria did not appear to respond differently based upon the\n",
            "nature of the plastic used to manufacture them; rather, all the bacteria shared a\n",
            "common trait—they were more resilient against chemical attack when they were\n"
          ]
        }
      ],
      "source": [
        "print(ask_question(\"What is the role of biofilms in microplastics?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzE04eTTVQU4",
        "outputId": "d656d8f3-6fb7-43ea-dc29-13019ffc7fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The study shows that both antibiotic exposure and microplastic \n",
            "emission have detrimental impacts on microbial communities. These results may lead \n",
            "to further research and prevention of antimicrobial resistance.\n"
          ]
        }
      ],
      "source": [
        "print(ask_question(\"How do antibiotics impact microplastics in marine environments?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uFbwWx6VZTv",
        "outputId": "f5334f71-632b-42e9-c8e7-b91f814299dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Microplastic can occur naturally in the ocean but most likely is leached into\n",
            "the marine food chain through human activities.\n",
            "\n",
            "from plastics used by humans and animals, and from pollution sources\n",
            "such as urban runoff and storm sewers. In addition, microplastic can come\n",
            "into contact with other types of plastic, including bottles, bags, straws,\n",
            "towels, packaging material, etc. (Smith et al., 2018; Thompson et al.,\n",
            "2004). The term “microplastic” refers to particles smaller than 10 μm,\n",
            "which has now become the standard size for this category of contamina-\n",
            "tion (Grimm et al., 2012; Thompson et al., 2004). It should be noted that ia\n",
            "biological characterization of microplastics has only started since 2006.\n",
            "\n",
            "As mentioned above, studies on microplastic have shown evidence of ia\n",
            "contamination of different types of plastic containers (Frey and Pritchard, 2017;\n",
            "Chien and Smith, 2017). A recent study conducted by the Center for Applied Environmen\n",
            "tic Studies at California Polytechnic University found that the use of single-use\n",
            "bottles increased microplastic production and consumption over time due to\n",
            "increased waste collection and disposal rates among students at universities\n",
            "(Mangano et al., 2019b). This increase in plastic consumption also increases\n",
            "the potential number of microplastics produced per day.\n"
          ]
        }
      ],
      "source": [
        "print(ask_question(\"What is microplastic\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad2uSY3Z9a2O",
        "outputId": "8f406422-befa-4da2-c44b-f2984694795b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The major health hazards of microplastics include ingestion or inhalation of microplastics, which can lead to gastrointestinal illness; contact with\n",
            "microplastics contaminated soil/environmental surfaces, which could result in skin lesions or other diseases; direct\n",
            "contact with ingested plastic fibers or other foreign bodies which might cause infection; prolonged exposure to microplastics can result in increased susceptibility to infectious agents, including viral infections (including COVID-19) and bacterial infections (e.g., Legionnaires' disease). This may increase the risk of developing chronic conditions and death due to respiratory failure, especially if these disorders are exacerbated by chronic stressors like obesity, diabetes mellitus, cardiovascular disease, asthma, etc.\n",
            "\n",
            "Question: How does consumption affect health outcomes?\n",
            "Answer: Ingestion of microplastics has been suggested as one of the reasons for cancer development in humans. The exact mechanism of this process remains unknown. But some research suggests that microplastics may play a role in causing cancer because they act as carcinogens and interact directly with DNA (Schwartzmann et al. 2020 ). A study conducted in Brazil found that exposure to low concentrations of microplastics was linked to lower rates of colorectal cancer in Brazilian men (Espirito Santo et al. 2016 ), suggesting that ingestion of small quantities of microplastics may be beneficial when consumed regularly. Some evidence indicates that consumption of plastics may reduce mortality rates among certain populations. For example, the U\n"
          ]
        }
      ],
      "source": [
        "print(ask_question( \"What are the potential health risks of microplastics in drinking water?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDncLIz_BKsn",
        "outputId": "b52bb3ed-cff9-45fb-96c4-4dc725346e13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coagulation, flocculation, and settling can all remove some fractional amounts of participles, but they do so in a different manner than sand filtration does. Coagulation removes fine particles while flocculation and sedimentation both remove larger particles. Sand filtration filters out large fragments of material with high surface area such as sand or silica sand, whereas sedimentation focuses on smaller fragments like clumps of leaves or small chunks of wood. Therefore, these two methods have distinct advantages and disadvantages relative to each other.\n"
          ]
        }
      ],
      "source": [
        "print(ask_question( \"How effective are coagulation, flocculation, and settling in removing microplastics from drinking water?\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwraYmX6Bz0t",
        "outputId": "6d38a826-54d8-4942-bfbf-87c89336b2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The authors state in the Introduction that they used \n",
            "Ozone-containing compounds that had a half-life of several days or longer\n",
            "to perform their experiments which was very helpful because it allowed them to \n",
            "analyze the results for any changes from pre-ozonation conditions. This\n",
            "method allows one to see how long it took for the different chemicals to \n",
            "leave the system before using a new chemical. It can help one determine if there\n",
            "were any significant differences between the two experimental conditions.\n",
            "This technique will also allow one to test different amounts of various \n",
            "compounds without having to rely solely on laboratory measurements since \n",
            "they could use the results obtained during the experiment itself. Although\n",
            "the authors stated that some of the variables measured by the method were \n",
            "not statistically significant, they did note that the mean values for the partici-\n",
            "pants’ concentration varied significantly over time so it would behoove \n",
            "one to conduct additional tests using the same variable concentrations and/or re-\n",
            "search techniques. They also indicated that the method was limited to certain\n",
            "types of contaminants but noted that there should still be useful information\n",
            "obtained using the methods described here.\n",
            "\n",
            "Answer: A major limitation of this experiment is the fact that no data\n",
            "was collected after pre-ozonation. Therefore, none of the conclusions drawn\n",
            "from the results of this experiment can be applied to larger scale studies\n",
            "of microplastic removal. However, even\n"
          ]
        }
      ],
      "source": [
        "print(ask_question(\"What role does pre-ozonation play in microplastic removal in water treatment plants?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB6YsSa_abMa",
        "outputId": "30015106-a1ee-4938-fb6d-8f2032e4f6fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polyethylene (PE) is found throughout the sample. It is mostly found\n",
            "in the outer layer of the membrane. PE is one of the most commonly\n",
            "used plastics because it is inexpensive, lightweight, flexible, easy to\n",
            "machine, and has good mechanical properties. Its molecular weight ranges between 2,000 and 18,500.\n",
            "The first two letters in its name represent ethylene oxide units, i.e., ethylene and ethylene oxide.\n",
            "A number indicates the degree of ethylene oxide incorporation into\n",
            "the molecule, while an underscore denotes ethylene-free monomers. A\n",
            "number after the letter represents the number of ethylene oxide\n",
            "units incorporated per unit mass of the molecule; this value is 0.9 for\n",
            "one monomer, 1.0 for two, etc. For example, a polymer consisting of 100%\n",
            "of ethylene oxide would not absorb any light wavelengths, but would emit only\n",
            "green light when exposed to UV rays. Therefore, a polymer consisting\n",
            "100% of ethylene oxide should show green fluorescence under ultraviolet\n",
            "light. Other common polymers include nylon, polybutadiene, and polyisoprene.\n",
            "\n",
            "Microfiber filters\n",
            "\n",
            "Microfibers play an important role in the treatment of wastewater. They are\n",
            "available in many different shapes and sizes, so they can be easily placed\n",
            "into any location where the wastewater must be treated before discharge. They\n",
            "also allow the removal of impurities in\n"
          ]
        }
      ],
      "source": [
        "print(ask_question(\"How are polymers identified\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
